# -*- coding: utf-8 -*-
"""Time series.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lzmdqLEt4vddrmGWqLpYacZ0AMf40uWy
"""

# Step 1: Importing the necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA

# Step 2: Loading the data
data = pd.read_csv('/content/project4.csv', parse_dates=['Date'], index_col='Date')

# Step 3: Exploratory Data Analysis (EDA)
# Plotting the time series data
plt.figure(figsize=(14, 7))
plt.plot(data['AMZN'], label='AMZN')
plt.plot(data['DPZ'], label='DPZ')
plt.plot(data['BTC'], label='BTC')
plt.plot(data['NFLX'], label='NFLX')
plt.legend(loc='best')
plt.title('Stock Prices Over Time')
plt.show()


# Checking for missing values
print(data.isnull().sum())

# Step 4: Time Series Analysis
# Decomposing the time series for Amazon (AMZN) as an example
decomposition = seasonal_decompose(data['AMZN'], model='multiplicative', period=365)
fig = decomposition.plot()
plt.show()

# Step 5: ARIMA Model for Forecasting
# Example for Amazon (AMZN)
# Splitting the data into training and testing sets
train = data['AMZN'][:int(0.8*len(data))]
test = data['AMZN'][int(0.8*len(data)):]


# Fitting the ARIMA model
model = ARIMA(train, order=(5, 1, 0))
model_fit = model.fit()
print(model_fit.summary())

# Making predictions
predictions = model_fit.forecast(steps=len(test))
plt.figure(figsize=(12, 6))
plt.plot(train, label='Train')
plt.plot(test, label='Test')
plt.plot(test.index, predictions, label='Predictions')
plt.legend(loc='best')
plt.title('AMZN Stock Price Prediction')
plt.show()

# Step 6: Evaluate the model
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(test, predictions)
print(f'Mean Squared Error: {mse}')